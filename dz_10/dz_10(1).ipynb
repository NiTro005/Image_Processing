{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport cv2\nimport os\nfrom skimage.feature import graycomatrix, graycoprops\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, jaccard_score\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['font.size'] = 12\n\nDATA_FOLDER = \"./KTH_TIPS\"\nTEST_IMAGE = \"test_bread.png\"\n\nprint(\"Проверка существования папок:\")\nprint(f\"Папка KTH_TIPS существует: {os.path.exists(DATA_FOLDER)}\")\nprint(f\"Тестовое изображение существует: {os.path.exists(TEST_IMAGE)}\")\n\nif os.path.exists(DATA_FOLDER):\n    print(\"\\nПапки в KTH-TIPS:\")\n    for folder in os.listdir(DATA_FOLDER):\n        folder_path = os.path.join(DATA_FOLDER, folder)\n        if os.path.isdir(folder_path):\n            files = os.listdir(folder_path)\n            png_files = [f for f in files if f.lower().endswith('.png')]\n            print(f\"  {folder}: {len(png_files)} изображений\")\nelse:\n    print(f\"ВНИМАНИЕ: Папка {DATA_FOLDER} не найдена!\")\n    print(\"Создайте папку KTH_TIPS и добавьте в неё текстуры\")\n    \nif not os.path.exists(TEST_IMAGE):\n    print(f\"\\nВНИМАНИЕ: Тестовое изображение {TEST_IMAGE} не найдено!\")\n    print(\"Добавьте файл test_bread.png в текущую директорию\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Проверка существования папок:\nПапка KTH_TIPS существует: True\nТестовое изображение существует: True\n\nПапки в KTH-TIPS:\n  aluminium_foil: 81 изображений\n  brown_bread: 81 изображений\n  corduroy: 81 изображений\n  cotton: 81 изображений\n  cracker: 81 изображений\n  linen: 81 изображений\n  orange_peel: 81 изображений\n  sandpaper: 81 изображений\n  sponge: 81 изображений\n  styrofoam: 81 изображений\n"
        }
      ],
      "execution_count": 51
    },
    {
      "cell_type": "code",
      "source": "def extract_histogram_features(gray_image):\n    if gray_image is None or gray_image.size == 0:\n        return np.zeros(10)\n    \n    hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n    hist = hist.flatten() / hist.sum()\n    \n    values = np.arange(256)\n    mean = np.sum(hist * values)\n    variance = np.sum(hist * (values - mean)**2)\n    std = np.sqrt(variance)\n    \n    skewness = 0\n    kurtosis = -3\n    if std > 0:\n        skewness = np.sum(hist * ((values - mean) / std)**3)\n        kurtosis = np.sum(hist * ((values - mean) / std)**4) - 3\n    \n    non_zero = hist[hist > 0]\n    entropy = -np.sum(non_zero * np.log2(non_zero)) if len(non_zero) > 0 else 0\n    \n    cumulative = np.cumsum(hist)\n    q1 = np.argmax(cumulative >= 0.25) if np.any(cumulative >= 0.25) else 0\n    median = np.argmax(cumulative >= 0.5) if np.any(cumulative >= 0.5) else 0\n    q3 = np.argmax(cumulative >= 0.75) if np.any(cumulative >= 0.75) else 0\n    \n    non_zero_bins = np.where(hist > 0)[0]\n    min_val = non_zero_bins[0] if len(non_zero_bins) > 0 else 0\n    max_val = non_zero_bins[-1] if len(non_zero_bins) > 0 else 255\n    \n    return np.array([mean, std, skewness, kurtosis, entropy, q1, median, q3, min_val, max_val])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 52
    },
    {
      "cell_type": "code",
      "source": "def extract_laws_features(image):\n    if image is None or image.size == 0:\n        return np.zeros(25)\n    \n    L5 = np.array([1, 4, 6, 4, 1])\n    E5 = np.array([-1, -2, 0, 2, 1])\n    S5 = np.array([-1, 0, 2, 0, -1])\n    W5 = np.array([-1, 2, 0, -2, 1])\n    R5 = np.array([1, -4, 6, -4, 1])\n    \n    masks = [L5, E5, S5, W5, R5]\n    features = []\n    \n    for i, mask1 in enumerate(masks):\n        for j, mask2 in enumerate(masks):\n            kernel = np.outer(mask1, mask2)\n            filtered = cv2.filter2D(image.astype(np.float32), -1, kernel)\n            energy = np.mean(filtered ** 2)\n            features.append(energy)\n    \n    features = np.array(features)\n    if np.sum(features) > 0:\n        features = features / np.sum(features)\n    \n    return features",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 53
    },
    {
      "cell_type": "code",
      "source": "def extract_glcm_features(image):\n    if image is None or image.size == 0:\n        return np.zeros(5)\n    \n    image_quantized = (image // 8).astype(np.uint8)\n    \n    try:\n        glcm = graycomatrix(image_quantized, \n                           distances=[1], \n                           angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n                           levels=32, \n                           symmetric=True, \n                           normed=True)\n        \n        features = []\n        props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n        \n        for prop in props:\n            feature_val = graycoprops(glcm, prop)\n            features.append(np.mean(feature_val))\n        \n        return np.array(features)\n    except Exception as e:\n        print(f\"Ошибка при вычислении GLCM: {e}\")\n        return np.zeros(5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 54
    },
    {
      "cell_type": "code",
      "source": "def load_kth_tips_dataset(folder_path):\n    X_hist, X_laws, X_glcm, y = [], [], [], []\n    \n    if not os.path.exists(folder_path):\n        print(f\"Ошибка: папка {folder_path} не найдена!\")\n        return np.array(X_hist), np.array(X_laws), np.array(X_glcm), np.array(y)\n    \n    class_folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n    \n    if not class_folders:\n        print(f\"В папке {folder_path} нет подпапок с классами!\")\n        return np.array(X_hist), np.array(X_laws), np.array(X_glcm), np.array(y)\n    \n    for class_name in class_folders:\n        class_path = os.path.join(folder_path, class_name)\n            \n        print(f\"Загрузка {class_name}...\")\n        \n        image_files = [f for f in os.listdir(class_path) if f.lower().endswith('.png')]\n        \n        for file in image_files[:50]:\n            img_path = os.path.join(class_path, file)\n            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            \n            if image is None:\n                print(f\"  Не удалось загрузить {file}\")\n                continue\n                    \n            image = cv2.resize(image, (128, 128), interpolation=cv2.INTER_AREA)\n            \n            X_hist.append(extract_histogram_features(image))\n            X_laws.append(extract_laws_features(image))\n            X_glcm.append(extract_glcm_features(image))\n            y.append(class_name)\n    \n    return np.array(X_hist), np.array(X_laws), np.array(X_glcm), np.array(y)\n\nprint(\"\\nЗагрузка датасета KTH-TIPS...\")\nX_hist, X_laws, X_glcm, y = load_kth_tips_dataset(DATA_FOLDER)\n\nif len(y) > 0:\n    print(f\"\\nЗагружено {len(y)} изображений\")\n    print(f\"Гистограмма: {X_hist.shape}\")\n    print(f\"Laws: {X_laws.shape}\")\n    print(f\"GLCM: {X_glcm.shape}\")\n    print(f\"Уникальные классы: {np.unique(y)}\")\nelse:\n    print(\"\\nНе удалось загрузить данные! Проверьте структуру папок.\")\n    print(\"Ожидается: KTH_TIPS/class1/*.png, KTH_TIPS/class2/*.png, ...\")\n    \n    print(\"Создаю демо-данные для тестирования...\")\n    np.random.seed(42)\n    n_samples = 100\n    n_classes = 5\n    \n    X_hist = np.random.randn(n_samples, 10)\n    X_laws = np.random.randn(n_samples, 25)\n    X_glcm = np.random.randn(n_samples, 5)\n    y = np.array(['class_' + str(i % n_classes) for i in range(n_samples)])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nЗагрузка датасета KTH-TIPS...\nЗагрузка aluminium_foil...\nЗагрузка brown_bread...\nЗагрузка corduroy...\nЗагрузка cotton...\nЗагрузка cracker...\nЗагрузка linen...\nЗагрузка orange_peel...\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def train_classifiers(X, y, feature_name):\n    \"\"\"Обучение классификаторов на различных признаках\"\"\"\n    if len(np.unique(y)) < 2:\n        print(f\"  Ошибка: недостаточно классов ({len(np.unique(y))}) для обучения\")\n        return {}, None\n    \n    le = LabelEncoder()\n    y_encoded = le.fit_transform(y)\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded\n    )\n    \n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    classifiers = {\n        'kNN': KNeighborsClassifier(n_neighbors=3, n_jobs=-1),\n        'SVM': SVC(kernel='rbf', C=10, gamma='scale', random_state=42),\n        'Decision Tree': DecisionTreeClassifier(max_depth=15, random_state=42)\n    }\n    \n    results = {}\n    \n    for name, clf in classifiers.items():\n        try:\n            clf.fit(X_train_scaled, y_train)\n            y_pred = clf.predict(X_test_scaled)\n            accuracy = accuracy_score(y_test, y_pred)\n            \n            results[name] = {\n                'model': clf,\n                'scaler': scaler,\n                'accuracy': accuracy,\n                'predictions': y_pred,\n                'true_labels': y_test,\n                'label_encoder': le\n            }\n            \n            print(f\"  {name}: Точность = {accuracy:.4f}\")\n        except Exception as e:\n            print(f\"  Ошибка при обучении {name}: {e}\")\n    \n    return results, le\n\nprint(\"Обучение на гистограммных признаках:\")\nresults_hist, le_hist = train_classifiers(X_hist, y, \"Histogram\")\n\nprint(\"\\nОбучение на Laws признаках:\")\nresults_laws, le_laws = train_classifiers(X_laws, y, \"Laws\")\n\nprint(\"\\nОбучение на GLCM признаках:\")\nresults_glcm, le_glcm = train_classifiers(X_glcm, y, \"GLCM\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "comparison_data = []\n\nfor feature_name, results in [('Histogram', results_hist), ('Laws', results_laws), ('GLCM', results_glcm)]:\n    for model_name, result in results.items():\n        comparison_data.append({\n            'Тип признаков': feature_name,\n            'Модель': model_name,\n            'Точность': result['accuracy']\n        })\n\nif comparison_data:\n    df_comparison = pd.DataFrame(comparison_data)\n    print(\"\\nСравнение точности классификации:\")\n    print(df_comparison.sort_values('Точность', ascending=False).to_string(index=False))\n\n    plt.figure(figsize=(10, 6))\n    colors = {'Histogram': '#1f77b4', 'Laws': '#2ca02c', 'GLCM': '#ff7f0e'}\n\n    for feature_type, color in colors.items():\n        subset = df_comparison[df_comparison['Тип признаков'] == feature_type]\n        if len(subset) > 0:\n            plt.bar(subset['Модель'], subset['Точность'], color=color, \n                    alpha=0.7, label=feature_type, width=0.6)\n\n    plt.xlabel('Модель классификации')\n    plt.ylabel('Точность')\n    plt.title('Сравнение точности классификации')\n    plt.legend(title='Тип признаков')\n    plt.grid(True, alpha=0.3)\n    plt.ylim(0, 1.0)\n    plt.tight_layout()\n    plt.show()\n    \n    best_row = df_comparison.loc[df_comparison['Точность'].idxmax()]\n    best_feature = best_row['Тип признаков']\n    best_model = best_row['Модель']\n    \n    print(f\"\\nЛучшая модель: {best_feature} + {best_model}\")\n    print(f\"Точность: {best_row['Точность']:.4f}\")\n    \n    if best_feature == 'Histogram':\n        best_result = results_hist[best_model]\n    elif best_feature == 'Laws':\n        best_result = results_laws[best_model]\n    else:\n        best_result = results_glcm[best_model]\nelse:\n    print(\"Нет данных для сравнения!\")\n    best_feature = None\n    best_model = None",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def segment_image(image_path, model_info, feature_type, patch_size=32, step=16):\n    if not os.path.exists(image_path):\n        print(f\"Файл {image_path} не найден!\")\n        return None\n    \n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    if image is None:\n        print(f\"Не удалось загрузить изображение {image_path}\")\n        return None\n    \n    h, w = image.shape\n    seg_map = np.zeros((h, w), dtype=np.uint8)\n    \n    model = model_info['model']\n    scaler = model_info['scaler']\n    \n    for y in range(0, h - patch_size + 1, step):\n        for x in range(0, w - patch_size + 1, step):\n            patch = image[y:y+patch_size, x:x+patch_size]\n            \n            if feature_type == 'Histogram':\n                features = extract_histogram_features(patch)\n            elif feature_type == 'Laws':\n                features = extract_laws_features(patch)\n            else:  # GLCM\n                features = extract_glcm_features(patch)\n            \n            features_scaled = scaler.transform(features.reshape(1, -1))\n            pred_class = model.predict(features_scaled)[0]\n            seg_map[y:y+patch_size, x:x+patch_size] = pred_class\n    \n    return seg_map",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "if os.path.exists(TEST_IMAGE) and best_feature is not None:\n    print(f\"Обработка тестового изображения: {TEST_IMAGE}\")\n    \n    original_img = cv2.imread(TEST_IMAGE, cv2.IMREAD_GRAYSCALE)\n    if original_img is not None:\n        segmentation = segment_image(TEST_IMAGE, best_result, best_feature)\n        \n        if segmentation is not None:\n            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n            \n            axes[0].imshow(original_img, cmap='gray')\n            axes[0].set_title('Оригинальное изображение')\n            axes[0].axis('off')\n            \n            axes[1].imshow(segmentation, cmap='tab20')\n            axes[1].set_title('Сегментация')\n            axes[1].axis('off')\n            \n            axes[2].imshow(original_img, cmap='gray', alpha=0.7)\n            axes[2].imshow(segmentation, cmap='tab20', alpha=0.5)\n            axes[2].set_title('Наложение')\n            axes[2].axis('off')\n            \n            plt.suptitle(f'Сегментация: {best_feature} + {best_model}', fontsize=14)\n            plt.tight_layout()\n            plt.show()\n        else:\n            print(\"Не удалось выполнить сегментацию\")\n    else:\n        print(f\"Не удалось загрузить изображение {TEST_IMAGE}\")\nelse:\n    print(f\"Тестовое изображение {TEST_IMAGE} не найдено или модель не обучена.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def manual_segment(image):\n    if image is None:\n        return None\n    \n    if len(image.shape) == 3:\n        image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    else:\n        image_gray = image\n    \n    _, mask = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n    \n    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    final_mask = np.zeros_like(mask)\n\n    if contours:\n        largest_contour = max(contours, key=cv2.contourArea)\n        cv2.drawContours(final_mask, [largest_contour], 0, 1, -1)\n    \n    return final_mask\n\ndef keep_top_colors(mask, n_colors=4):\n    if mask is None or mask.size == 0:\n        return mask\n    \n    unique, counts = np.unique(mask, return_counts=True)\n    \n    if len(unique) <= n_colors:\n        return mask\n    \n    sorted_indices = np.argsort(-counts)\n    top_colors = unique[sorted_indices[:n_colors]]\n    \n    print(f\"Топ-{n_colors} самых частых цветов: {top_colors}\")\n    print(f\"Их частоты: {counts[sorted_indices[:n_colors]]}\")\n    \n    result = np.zeros_like(mask)\n    for new_value, old_value in enumerate(top_colors):\n        result[mask == old_value] = new_value\n    \n    print(f\"Перенумеровано: {top_colors} -> {list(range(len(top_colors)))}\")\n    \n    return result",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "if os.path.exists(TEST_IMAGE):\n    image = cv2.imread(TEST_IMAGE)\n    if image is not None:\n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        manual_mask = manual_segment(image_rgb)\n        \n        if manual_mask is not None:\n            fig, (ax_orig, ax_segment) = plt.subplots(1, 2, figsize=(10, 5))\n\n            ax_orig.imshow(image_rgb)\n            ax_orig.set_title('Оригинальное изображение')\n            ax_orig.axis('off')\n\n            ax_segment.imshow(manual_mask, cmap='gray')\n            ax_segment.set_title('\"Ручная\" разметка (Otsu + контуры)')\n            ax_segment.axis('off')\n\n            plt.tight_layout()\n            plt.show()\n            \n            cv2.imwrite(\"manual_mask_result.png\", manual_mask * 255)\n            print(\"Ручная разметка сохранена в manual_mask_result.png\")\n        else:\n            print(\"Не удалось создать ручную разметку\")\n    else:\n        print(f\"Не удалось загрузить изображение {TEST_IMAGE}\")\nelse:\n    print(f\"Тестовое изображение {TEST_IMAGE} не найдено\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def compare_segmentations(manual_mask, auto_segmentation):\n    if manual_mask is None or auto_segmentation is None:\n        print(\"Ошибка: одна из сегментаций отсутствует\")\n        return 0, 0, None, None\n    \n    h, w = auto_segmentation.shape\n    \n    if len(manual_mask.shape) == 3:\n        manual_gray = cv2.cvtColor(manual_mask, cv2.COLOR_BGR2GRAY)\n    else:\n        manual_gray = manual_mask\n    \n    manual_resized = cv2.resize(manual_gray, (w, h), interpolation=cv2.INTER_NEAREST)\n    \n    manual_binary = (manual_resized > 0).astype(np.uint8)\n    \n    unique, counts = np.unique(auto_segmentation, return_counts=True)\n    if len(unique) > 1:\n        background = unique[np.argmax(counts)]\n        auto_binary = (auto_segmentation != background).astype(np.uint8)\n    else:\n        auto_binary = (auto_segmentation > 0).astype(np.uint8)\n    \n    agreement_direct = accuracy_score(manual_binary.flatten(), auto_binary.flatten())\n    agreement_inverted = accuracy_score(manual_binary.flatten(), 1 - auto_binary.flatten())\n    \n    if agreement_inverted > agreement_direct:\n        auto_binary = 1 - auto_binary\n    \n    accuracy = accuracy_score(manual_binary.flatten(), auto_binary.flatten())\n    \n    intersection = np.logical_and(manual_binary, auto_binary).sum()\n    union = np.logical_or(manual_binary, auto_binary).sum()\n    iou = intersection / union if union > 0 else 0\n    \n    return accuracy, iou, manual_binary, auto_binary\n\n# Сравнение сегментаций\nif os.path.exists(TEST_IMAGE) and best_feature is not None and 'manual_mask' in locals():\n    segmentation = segment_image(TEST_IMAGE, best_result, best_feature)\n    \n    if segmentation is not None and manual_mask is not None:\n        accuracy, iou, manual_binary, seg_binary = compare_segmentations(\n            manual_mask, segmentation\n        )\n        \n        print(f\"\\nМетрики качества сегментации:\")\n        print(f\"  Точность (Accuracy): {accuracy:.4f}\")\n        print(f\"  IoU (Jaccard): {iou:.4f}\")\n        \n        original_img = cv2.imread(TEST_IMAGE, cv2.IMREAD_GRAYSCALE)\n        \n        if original_img is not None:\n            fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n            \n            axes[0, 0].imshow(original_img, cmap='gray')\n            axes[0, 0].set_title('Оригинальное изображение')\n            axes[0, 0].axis('off')\n            \n            axes[0, 1].imshow(manual_binary, cmap='gray')\n            axes[0, 1].set_title('Ручная разметка (бинарная)')\n            axes[0, 1].axis('off')\n            \n            axes[0, 2].imshow(seg_binary, cmap='gray')\n            axes[0, 2].set_title('Автоматическая сегментация (бинарная)')\n            axes[0, 2].axis('off')\n            \n            axes[1, 0].imshow(original_img, cmap='gray', alpha=0.7)\n            axes[1, 0].imshow(manual_binary, cmap='Reds', alpha=0.5)\n            axes[1, 0].set_title('Оригинал + Ручная разметка')\n            axes[1, 0].axis('off')\n            \n            axes[1, 1].imshow(original_img, cmap='gray', alpha=0.7)\n            axes[1, 1].imshow(seg_binary, cmap='Blues', alpha=0.5)\n            axes[1, 1].set_title('Оригинал + Автосегментация')\n            axes[1, 1].axis('off')\n            \n            diff = manual_binary != seg_binary\n            axes[1, 2].imshow(diff, cmap='Reds')\n            axes[1, 2].set_title(f'Различия (красный)\\nAccuracy: {accuracy:.3f}, IoU: {iou:.3f}')\n            axes[1, 2].axis('off')\n            \n            plt.suptitle(f'Сравнение сегментаций: {best_feature} + {best_model}', fontsize=14)\n            plt.tight_layout()\n            plt.show()\n        else:\n            print(\"Не удалось загрузить оригинальное изображение для визуализации\")\n    else:\n        print(\"Ошибка: не удалось получить сегментацию или ручную разметку\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}